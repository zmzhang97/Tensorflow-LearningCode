{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "* tf.train.GradientDescentOptimizer\n",
    "* tf.train.AdadeltaOptimizer\n",
    "* tf.train.AdagradDAOptimizer\n",
    "* tf.train.MomentumOptimizer\n",
    "* tf.train.AdamOptimizer\n",
    "* tf.train.FtrlOptimizer\n",
    "* tf.train.ProximalAdagradOptimizer\n",
    "* tf.train.RMSPropOptimizer\n",
    "\n",
    "### 各种优化器对比\n",
    "* 标准梯度下降法：先计算所有样本汇总误差，然后根据总误差来更新权值；\n",
    "* 随机梯度下降法：随机抽取一个样本来计算误差，然后更新权值；\n",
    "* 批量梯度下降法：一种折中的方案，从总样本中选取一个批次（比如一共有10000个样本，随机选取100个样本作为一个batch），然后计算这个batch的总误差，根据总误差来更新权值。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T03:19:49.776029Z",
     "start_time": "2020-10-12T03:19:17.516062Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data   #手写数字相关的数据包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T03:25:54.941027Z",
     "start_time": "2020-10-12T03:24:49.998647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0,Testing Accuracy0.9208\n",
      "Iter1,Testing Accuracy0.9262\n",
      "Iter2,Testing Accuracy0.9214\n",
      "Iter3,Testing Accuracy0.9249\n",
      "Iter4,Testing Accuracy0.9283\n",
      "Iter5,Testing Accuracy0.932\n",
      "Iter6,Testing Accuracy0.9302\n",
      "Iter7,Testing Accuracy0.9328\n",
      "Iter8,Testing Accuracy0.9311\n",
      "Iter9,Testing Accuracy0.9299\n",
      "Iter10,Testing Accuracy0.932\n",
      "Iter11,Testing Accuracy0.9299\n",
      "Iter12,Testing Accuracy0.9335\n",
      "Iter13,Testing Accuracy0.9281\n",
      "Iter14,Testing Accuracy0.9318\n",
      "Iter15,Testing Accuracy0.9313\n",
      "Iter16,Testing Accuracy0.9329\n",
      "Iter17,Testing Accuracy0.9324\n",
      "Iter18,Testing Accuracy0.9334\n",
      "Iter19,Testing Accuracy0.9314\n",
      "Iter20,Testing Accuracy0.9312\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)    #载入数据，{数据集包路径，把标签转化为只有0和1的形式}\n",
    "\n",
    "#定义变量，即每个批次的大小\n",
    "batch_size = 100    #一次放100章图片进去\n",
    "n_batch = mnist.train.num_examples // batch_size   #计算一共有多少个批次；训练集数量（整除）一个批次大小\n",
    "\n",
    "#定义两个placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784])    #[行不确定，列为784]\n",
    "y = tf.placeholder(tf.float32,[None,10])    #数字为0-9，则为10\n",
    "\n",
    "#创建简单的神经网络\n",
    "W = tf.Variable(tf.zeros([784,10]))   #权重\n",
    "b = tf.Variable(tf.zeros([10]))     #偏置\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W)+b)    #预测\n",
    "\n",
    "#定义二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "#定义交叉熵代价函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "#使用梯度下降法\n",
    "# train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "#使用不同优化器\n",
    "train_step = tf.train.AdamOptimizer(1e-2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#准确数，结果存放在一个布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))   #比较两个参数大小是否相同，同则返回为true，不同则返回为false；argmax()：返回张量中最大的值所在的位置\n",
    "\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))   #cast()：将布尔型转换为32位的浮点型；（比方说9个T和1个F，则为9个1，1个0，即准确率为90%）\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter\" + str(epoch) + \",Testing Accuracy\" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
